{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### keyword frequency\n",
    "#### sentiment analysis\n",
    "#### latent topic analysis\n",
    "\n",
    "Week 8-9 - NLTK & keyword frequency\n",
    "\n",
    "API - https://www.nltk.org/\n",
    "Tutorial - https://realpython.com/nltk-nlp-python/\n",
    "\n",
    "\n",
    "Week 10-11 - sentiment analysis\n",
    "\n",
    "Milestone 2 - Project Update\n",
    "\n",
    "\n",
    "Week 12-13 - latent topic analysis\n",
    "\n",
    "\n",
    "Week 14 - advanced applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install nltk - run in command prompt (PC) or terminal (Mac)\n",
    "### python -m pip install nltk==3.6\n",
    "### python -m pip install numpy matplotlib\n",
    "### python -m pip install pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\seoul\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (3.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\seoul\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nltk) (2022.9.13)\n",
      "Requirement already satisfied: click in c:\\users\\seoul\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\seoul\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\seoul\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\seoul\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from click->nltk) (3.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\seoul\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\seoul\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from importlib-metadata->click->nltk) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\seoul\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from importlib-metadata->click->nltk) (3.7.4.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 22.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install -U nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_string = \"Muad'Dib learned rapidly because his first training was in how to learn. And the first lesson of all was the basic trust that he could learn. It's shocking to find how many people do not believe they can learn, and how many more believe learning to be difficult\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Muad'Dib learned rapidly because his first training was in how to learn. And the first lesson of all was the basic trust that he could learn. It's shocking to find how many people do not believe they can learn, and how many more believe learning to be difficult\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Muad'Dib learned rapidly because his first training was in how to learn.\",\n",
       " 'And the first lesson of all was the basic trust that he could learn.',\n",
       " \"It's shocking to find how many people do not believe they can learn, and how many more believe learning to be difficult\"]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(example_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Muad'Dib\",\n",
       " 'learned',\n",
       " 'rapidly',\n",
       " 'because',\n",
       " 'his',\n",
       " 'first',\n",
       " 'training',\n",
       " 'was',\n",
       " 'in',\n",
       " 'how',\n",
       " 'to',\n",
       " 'learn',\n",
       " '.',\n",
       " 'And',\n",
       " 'the',\n",
       " 'first',\n",
       " 'lesson',\n",
       " 'of',\n",
       " 'all',\n",
       " 'was',\n",
       " 'the',\n",
       " 'basic',\n",
       " 'trust',\n",
       " 'that',\n",
       " 'he',\n",
       " 'could',\n",
       " 'learn',\n",
       " '.',\n",
       " 'It',\n",
       " \"'s\",\n",
       " 'shocking',\n",
       " 'to',\n",
       " 'find',\n",
       " 'how',\n",
       " 'many',\n",
       " 'people',\n",
       " 'do',\n",
       " 'not',\n",
       " 'believe',\n",
       " 'they',\n",
       " 'can',\n",
       " 'learn',\n",
       " ',',\n",
       " 'and',\n",
       " 'how',\n",
       " 'many',\n",
       " 'more',\n",
       " 'believe',\n",
       " 'learning',\n",
       " 'to',\n",
       " 'be',\n",
       " 'difficult']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(example_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\seoul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "worf_quote = \"Sir, I protest. I am not a merry man!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_in_quote  = word_tokenize(worf_quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sir', ',', 'I', 'protest', '.', 'I', 'am', 'not', 'a', 'merry', 'man', '!']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_in_quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in words_in_quote:\n",
    "    if word.casefold() not in stop_words:\n",
    "        filtered_list.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sir', ',', 'protest', '.', 'merry', 'man', '!']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a sentence - and part-of-speech tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Muad'Dib learned rapidly because his first training was in how to learn. And the first lesson of all was the basic trust that he could learn. It's shocking to find how many people do not believe they can learn, and how many more believe learning to be difficult\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_in_quote = word_tokenize(example_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Muad'Dib\",\n",
       " 'learned',\n",
       " 'rapidly',\n",
       " 'because',\n",
       " 'his',\n",
       " 'first',\n",
       " 'training',\n",
       " 'was',\n",
       " 'in',\n",
       " 'how',\n",
       " 'to',\n",
       " 'learn',\n",
       " '.',\n",
       " 'And',\n",
       " 'the',\n",
       " 'first',\n",
       " 'lesson',\n",
       " 'of',\n",
       " 'all',\n",
       " 'was',\n",
       " 'the',\n",
       " 'basic',\n",
       " 'trust',\n",
       " 'that',\n",
       " 'he',\n",
       " 'could',\n",
       " 'learn',\n",
       " '.',\n",
       " 'It',\n",
       " \"'s\",\n",
       " 'shocking',\n",
       " 'to',\n",
       " 'find',\n",
       " 'how',\n",
       " 'many',\n",
       " 'people',\n",
       " 'do',\n",
       " 'not',\n",
       " 'believe',\n",
       " 'they',\n",
       " 'can',\n",
       " 'learn',\n",
       " ',',\n",
       " 'and',\n",
       " 'how',\n",
       " 'many',\n",
       " 'more',\n",
       " 'believe',\n",
       " 'learning',\n",
       " 'to',\n",
       " 'be',\n",
       " 'difficult']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_in_quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://realpython.com/nltk-nlp-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"Muad'Dib\", 'NNP'),\n",
       " ('learned', 'VBD'),\n",
       " ('rapidly', 'RB'),\n",
       " ('because', 'IN'),\n",
       " ('his', 'PRP$'),\n",
       " ('first', 'JJ'),\n",
       " ('training', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('in', 'IN'),\n",
       " ('how', 'WRB'),\n",
       " ('to', 'TO'),\n",
       " ('learn', 'VB'),\n",
       " ('.', '.'),\n",
       " ('And', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('first', 'JJ'),\n",
       " ('lesson', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('all', 'DT'),\n",
       " ('was', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('basic', 'JJ'),\n",
       " ('trust', 'NN'),\n",
       " ('that', 'IN'),\n",
       " ('he', 'PRP'),\n",
       " ('could', 'MD'),\n",
       " ('learn', 'VB'),\n",
       " ('.', '.'),\n",
       " ('It', 'PRP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('shocking', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('find', 'VB'),\n",
       " ('how', 'WRB'),\n",
       " ('many', 'JJ'),\n",
       " ('people', 'NNS'),\n",
       " ('do', 'VBP'),\n",
       " ('not', 'RB'),\n",
       " ('believe', 'VB'),\n",
       " ('they', 'PRP'),\n",
       " ('can', 'MD'),\n",
       " ('learn', 'VB'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('how', 'WRB'),\n",
       " ('many', 'JJ'),\n",
       " ('more', 'JJR'),\n",
       " ('believe', 'NNS'),\n",
       " ('learning', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('be', 'VB'),\n",
       " ('difficult', 'JJ')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(words_in_quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_in_quote = word_tokenize(example_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatize?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 40 samples and 52 outcomes>\n"
     ]
    }
   ],
   "source": [
    "frequency_distribution = FreqDist(words_in_quote)\n",
    "print(frequency_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('how', 3),\n",
       " ('to', 3),\n",
       " ('learn', 3),\n",
       " ('first', 2),\n",
       " ('was', 2),\n",
       " ('.', 2),\n",
       " ('the', 2),\n",
       " ('many', 2),\n",
       " ('believe', 2),\n",
       " (\"Muad'Dib\", 1),\n",
       " ('learned', 1),\n",
       " ('rapidly', 1),\n",
       " ('because', 1),\n",
       " ('his', 1),\n",
       " ('training', 1),\n",
       " ('in', 1),\n",
       " ('And', 1),\n",
       " ('lesson', 1),\n",
       " ('of', 1),\n",
       " ('all', 1)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency_distribution.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HW1. Run POS on some paragraphs in your corpus\n",
    "# HW2. Calculate top 20 words in your corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
